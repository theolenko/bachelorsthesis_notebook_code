{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbebc289",
   "metadata": {},
   "source": [
    "# Merging and Transforming Parliamentary Data\n",
    "\n",
    "This notebook consolidates all JSON data extracted from various state parliaments, transforms the structure, cleans up inconsistencies, and sorts entries chronologically. The result is a unified file `combined_transformed_data.json` ready for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4391d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import os      \n",
    "import re      \n",
    "import json    \n",
    "from datetime import datetime  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fb9e8",
   "metadata": {},
   "source": [
    "**Define functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e6c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_links(element_id: str):\n",
    "    \"\"\"\n",
    "    Splits the 'ElementID' field into a list of dictionaries with 'label' and 'url'.\n",
    "    The scraper uses '|' as a separator between link and link description.\n",
    "    Returns a list of dictionaries with the keys 'label' and 'url'.\n",
    "    \"\"\"\n",
    "    # Split the string at each '|' and remove whitespace\n",
    "    parts = [p.strip() for p in element_id.split(\"|\") if p.strip()]\n",
    "    links = []\n",
    "    for p in parts:\n",
    "        # If there is a ':' in the substring, assume it is 'label:url'\n",
    "        if \":\" in p:\n",
    "            label, url = p.split(\":\", 1)\n",
    "            links.append({\"label\": label.strip(), \"url\": url.strip()})\n",
    "        else:\n",
    "            # If no label is present, only store the URL\n",
    "            links.append({\"label\": None, \"url\": p})\n",
    "    return links\n",
    "\n",
    "def parse_date(s: str):\n",
    "    \"\"\"\n",
    "    Converts a date string in the format 'DD.MM.YYYY' to a datetime object.\n",
    "    If the date cannot be parsed, returns datetime.min as fallback.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to parse the date\n",
    "        return datetime.strptime(s, \"%d.%m.%Y\")\n",
    "    except Exception:\n",
    "        # Fallback: return a minimal datetime value\n",
    "        return datetime.min\n",
    "\n",
    "def extract_date_from_text(text):\n",
    "    \"\"\"\n",
    "    Extracts dates from texts like '(vom 29. August 2023)' or 'vom 29. August 2023'.\n",
    "    Returns the date in the format '29.08.2023' if successful, otherwise an empty string.\n",
    "    \"\"\"\n",
    "    # Mapping of month names to month numbers\n",
    "    months = {\n",
    "        \"Januar\": \"01\", \"Februar\": \"02\", \"März\": \"03\", \"April\": \"04\",\n",
    "        \"Mai\": \"05\", \"Juni\": \"06\", \"Juli\": \"07\", \"August\": \"08\",\n",
    "        \"September\": \"09\", \"Oktober\": \"10\", \"November\": \"11\", \"Dezember\": \"12\"\n",
    "    }\n",
    "    \n",
    "    # Search for a date pattern in the text\n",
    "    match = re.search(r\"vom\\s*(\\d{1,2})\\.?\\s*([A-Za-zäöüÄÖÜ]+)\\s+(\\d{4})\", text)\n",
    "    if match:\n",
    "        day, month_str, year = match.groups()\n",
    "        month = months.get(month_str, \"\")\n",
    "        if month:\n",
    "            # Return in the format 'DD.MM.YYYY'\n",
    "            return f\"{int(day):02d}.{month}.{year}\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ede04",
   "metadata": {},
   "source": [
    "**Load and combine JSON files from all parliaments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71334fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./Brandenburg/Brandenburg_Data.json: 704 entries\n",
      "Loaded ./Sachsen/Sachsen_Data.json: 1717 entries\n",
      "Loaded ./Thueringen/Thueringen_Data.json: 763 entries\n",
      "Loaded ./Sachsen/Sachsen_Data.json: 1717 entries\n",
      "Loaded ./Thueringen/Thueringen_Data.json: 763 entries\n",
      "Loaded ./Sachsen-Anhalt/SachsenAnhalt_Data.json: 870 entries\n",
      "Loaded ./MeckPom/MeckPom_Data.json: 593 entries\n",
      "Total loaded entries: 4647\n",
      "Loaded ./Sachsen-Anhalt/SachsenAnhalt_Data.json: 870 entries\n",
      "Loaded ./MeckPom/MeckPom_Data.json: 593 entries\n",
      "Total loaded entries: 4647\n"
     ]
    }
   ],
   "source": [
    "# List of paths to the JSON files from each parliament\n",
    "json_paths = [\n",
    "    \"./Brandenburg/Brandenburg_Data.json\",\n",
    "    \"./Sachsen/Sachsen_Data.json\",\n",
    "    \"./Thueringen/Thueringen_Data.json\",\n",
    "    \"./Sachsen-Anhalt/SachsenAnhalt_Data.json\",\n",
    "    \"./MeckPom/MeckPom_Data.json\",\n",
    "]\n",
    "\n",
    "raw_data = []  # List to store all loaded entries\n",
    "\n",
    "# Iterate over each JSON file path\n",
    "for path in json_paths:\n",
    "    if not os.path.exists(path):\n",
    "        # If the file does not exist, print a warning and skip to the next file\n",
    "        print(f\"File not found: {path}\")\n",
    "        continue\n",
    "    # Open the JSON file and load its content\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = json.load(f)\n",
    "        # If the content is a list, extend the raw_data list with its items\n",
    "        if isinstance(content, list):\n",
    "            raw_data.extend(content)\n",
    "        else:\n",
    "            # If the content is a single object, append it as one entry\n",
    "            raw_data.append(content)\n",
    "    # Print how many entries were loaded from this file\n",
    "    print(f\"Loaded {path}: {len(content) if isinstance(content, list) else 1} entries\")\n",
    "\n",
    "# Print the total number of loaded entries from all files\n",
    "print(f\"Total loaded entries: {len(raw_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bad4f8",
   "metadata": {},
   "source": [
    "**Transform structure, normalize URLs, assign unique (counter) IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed entries: 4647\n"
     ]
    }
   ],
   "source": [
    "transformed = []  # List to store the transformed entries\n",
    "counter = {}      # Dictionary to count entries per parliament for unique IDs\n",
    "\n",
    "for entry in raw_data:\n",
    "    parliament = entry.get(\"Landtag\", \"XX\")  # Get parliament name, fallback 'XX' if missing\n",
    "    counter.setdefault(parliament, 0)          # Initialize counter for this parliament if not present\n",
    "    counter[parliament] += 1                   # Increment counter for this parliament\n",
    "    new_id = f\"{parliament}_{counter[parliament]}\"  # Create unique ID for entry e.g. SN_7, BB_1...\n",
    "    date = entry.get(\"Datum\", \"\").strip()          # Get and clean date string\n",
    "    if not date:\n",
    "        # If no date is present, try to extract it from the description text as fallback\n",
    "        date = extract_date_from_text(entry.get(\"Beschreibungstext\", \"\"))\n",
    "\n",
    "    links = parse_links(entry.get(\"ElementID\", \"\"))  # Parse links from the ElementID field\n",
    "    cleaned_links = []  # List to store cleaned/normalized links\n",
    "\n",
    "    for link in links:\n",
    "        # Special case: For MV and TH, fix links that start with '//' and have label 'https'\n",
    "        if parliament in [\"MV\", \"TH\"] and link.get(\"label\") == \"https\" and link.get(\"url\", \"\").startswith(\"//\"):\n",
    "            link[\"url\"] = \"https:\" + link[\"url\"]  # Prepend 'https:' to the URL\n",
    "            link[\"label\"] = \"Dokument\"            # Set label to 'Dokument' for clarity\n",
    "        cleaned_links.append(link)  # Add the (possibly fixed) link to the list\n",
    "\n",
    "    # Build the transformed entry with normalized fields\n",
    "    transformed_entry = {\n",
    "        \"ID\": new_id,\n",
    "        \"Landtag\": parliament,\n",
    "        \"Datum\": date,\n",
    "        \"Beschreibungstext\": entry.get(\"Beschreibungstext\", \"\"),\n",
    "        \"FilterDetails\": entry.get(\"FilterDetails\", []),\n",
    "        \"Links\": cleaned_links,\n",
    "    }\n",
    "\n",
    "    # Optionally add extracted text if present in the original entry\n",
    "    if \"ExtrahierterText\" in entry:\n",
    "        transformed_entry[\"ExtrahierterText\"] = entry[\"ExtrahierterText\"]\n",
    "\n",
    "    transformed.append(transformed_entry)  # Add the transformed entry to the result list\n",
    "\n",
    "print(f\"Transformed entries: {len(transformed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eec27b",
   "metadata": {},
   "source": [
    "**Final sorting and export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3318f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined_Data.json written successfully.\n"
     ]
    }
   ],
   "source": [
    "#sort the transformed data by date\n",
    "transformed.sort(key=lambda e: parse_date(e.get(\"Datum\", \"\")))\n",
    "\n",
    "# Write the combinded, transformed data to a new JSON file\n",
    "with open(\"combined_transformed_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(transformed, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"combined_transformed_data.json written successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
